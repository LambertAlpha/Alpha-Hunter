#!/usr/bin/env python3
"""
GPUç¯å¢ƒæµ‹è¯•è„šæœ¬
æµ‹è¯•PyTorchå’ŒMPS (Apple Silicon GPU)æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import torch
import sys
import time

def main():
    print("="*60)
    print("Alpha-Hunter GPU ç¯å¢ƒæµ‹è¯•")
    print("="*60)
    
    # åŸºæœ¬ä¿¡æ¯
    print(f"\nğŸ“¦ ç¯å¢ƒä¿¡æ¯:")
    print(f"  Pythonç‰ˆæœ¬: {sys.version.split()[0]}")
    print(f"  PyTorchç‰ˆæœ¬: {torch.__version__}")
    
    # MPSæ£€æŸ¥
    print(f"\nğŸ Apple Silicon GPU (MPS):")
    mps_available = torch.backends.mps.is_available()
    mps_built = torch.backends.mps.is_built()
    
    print(f"  MPSå¯ç”¨: {mps_available}")
    print(f"  MPSå·²æ„å»º: {mps_built}")
    
    if mps_available:
        print("\nâœ… GPUåŠ é€Ÿå·²å¯ç”¨!")
        print("   å»ºè®®ä½¿ç”¨: --device mps æˆ– --device auto")
        
        # é€Ÿåº¦æµ‹è¯•
        print("\nğŸƒ æ€§èƒ½æµ‹è¯•ä¸­...")
        size = 1000
        n_iterations = 10
        
        # CPUæµ‹è¯•
        x_cpu = torch.randn(size, size)
        start = time.time()
        for _ in range(n_iterations):
            y_cpu = torch.matmul(x_cpu, x_cpu)
        cpu_time = time.time() - start
        
        # MPSæµ‹è¯•
        try:
            x_mps = torch.randn(size, size, device='mps')
            torch.mps.synchronize()
            start = time.time()
            for _ in range(n_iterations):
                y_mps = torch.matmul(x_mps, x_mps)
            torch.mps.synchronize()
            mps_time = time.time() - start
            
            speedup = cpu_time / mps_time
            
            print(f"\nğŸ“Š æ€§èƒ½ç»“æœ ({n_iterations}æ¬¡çŸ©é˜µä¹˜æ³•):")
            print(f"  CPUæ—¶é—´: {cpu_time:.4f}s")
            print(f"  MPSæ—¶é—´: {mps_time:.4f}s")
            print(f"  åŠ é€Ÿå€æ•°: {speedup:.2f}x ğŸš€")
            
            if speedup > 2:
                print(f"\nğŸ‰ GPUåŠ é€Ÿæ•ˆæœæ˜¾è‘—!")
            elif speedup > 1:
                print(f"\nâœ… GPUåŠ é€Ÿæ­£å¸¸")
            else:
                print(f"\nâš ï¸  GPUä¼¼ä¹æ²¡æœ‰åŠ é€Ÿæ•ˆæœï¼Œæ£€æŸ¥ç³»ç»Ÿè®¾ç½®")
        
        except Exception as e:
            print(f"\nâŒ MPSæµ‹è¯•å¤±è´¥: {e}")
            print("   å°è¯•æ›´æ–°PyTorchæˆ–ä½¿ç”¨CPU")
    
    else:
        print("\nâš ï¸  MPSä¸å¯ç”¨")
        if not mps_built:
            print("   PyTorchæ²¡æœ‰ç¼–è¯‘MPSæ”¯æŒ")
            print("   è§£å†³æ–¹æ¡ˆ: pip install --pre torch torchvision")
        else:
            print("   ä½ çš„è®¾å¤‡å¯èƒ½ä¸æ”¯æŒMPS")
            print("   è¿™ä¸å½±å“åŠŸèƒ½ï¼Œåªæ˜¯é€Ÿåº¦è¾ƒæ…¢")
    
    # è®¾å¤‡æ¨è
    print("\nğŸ¯ è®­ç»ƒå»ºè®®:")
    if mps_available:
        print("  python train_tfa.py --device mps --batch_size 256")
    else:
        print("  python train_tfa.py --device cpu --batch_size 128")
    
    print("\n" + "="*60)
    print("æµ‹è¯•å®Œæˆ!")
    print("="*60)

if __name__ == '__main__':
    main()

